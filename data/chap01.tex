\chapter{绪论}

\section{课题研究背景}

\subsection{计算机硬件系统的并行化与异构化趋势}
计算机行业从它诞生伊始就保持着日新月异的发展势头。摩尔定律（Moore's Law）\upcite{moore1965}的神奇预言
在过去的半个世纪中准确地反映了半导体与集成电路工业的发展速度：
集成电路上的晶体管数量每18个月翻一番。在摩尔定律的作用下，单个微处理器（microprocessor）的时钟频率
越来越高，处理器性能也随之不断提高。早期计算机均采用单一微处理器作为计算部件，其性能的提高主要依赖
微处理器运算速度的提高。但随着计算机系统结构的日益复杂化，仅仅提高单个处理器的运算速度已经不足以使
整个计算机系统的性能得到明显提升。

首先，单个处理器的性能提高有其极限，由于功耗问题以及晶体管器件本身物理特性的限制，
单个微处理器的频率不可能无限提高；其次，随着计算机系统结构日益复杂和多样化，
访存延迟、存储器带宽等因素可能成为制约性能的主要瓶颈；此外，程序中可发掘的指令级
并行（ILP）能力有限，单一指令流已经难以充分利用高速处理器的处理能力。
因此，当今业界主流厂商已经将眼光投向并行硬件，包括多处理器（multi-processor）计算机、
多核处理器（multi-core processor）以及面向特定应用的协处理器（coprocessor），
希望通过为用户提供多个处理器或为特定应用需求提供专用处理器来获得更高的性能。

2001年IBM推出了首款通用双核（dual-core）处理器，此后，各大主流厂商相继推了不同系列的多核处理器，单个
处理器包括的核心数目不等，有的处理器核心数目可以达到16或者更多（如AMD Opteron系列，Intel Xeon系列等）。
短短几年之内，多核处理器已经占据市场主流位置，从超级计算机到高性能服务器，从桌面PC到移动通信设备，
多核处理器随处可见。

协处理器一般是针对特定应用而设计的处理器，如浮点计算、图形处理、信号处理、加密解密等。相较于通用
处理器，协处理器可能缺乏某些功能，但在处理某类计算问题时具备突出的性能优势。当前许多计算机系统都配备有一个或
多个协处理器，用以辅助CPU执行计算。图形处理器（Graphics Processor Unit, GPU）是当前应用最为广泛的一类协处理器，
它最开始被专门设计于图形处理问题，协助CPU完成图形渲染等工作。近年来GPU已经越来越成为一种“通用”计算设备，
主流GPU厂商与学术界已经为在GPU上执行通用计算提供软硬件支持采取了许多努力，取得了众多成果。
GPU采用流处理（stream processing）编程模型，这是一种类似于SIMD（Single Instruction Multiple Data）
的编程模型，也称为SPMD\upcite{auguin1983}。在流处理模型中，一组数据中的每一个单元都被
施加同一操作，一般将这种操作称之为Kernel。Kernel可以是一段程序，允许有一定的程序逻辑，而不限于单一指令，
这比SIMD提供了更高的灵活性。在硬件设计上，GPU通常拥多个流处理器（multiprocessor），
每个流处理器上有数百甚至上千个核心，Kernel被流水化执行，这可以大大加速数据并行问题的执行速度。

随着多核处理器与面向特定问题的协处理器的兴起，由通用处理器与协处理器组成异构硬件系统
（heterogeneous architecture）也已经成为当前计算机系统的主流构成模式。
由国防科学技术大学研制，在2013年度Top500评比中
排名第一的天河二号超级计算机，就采用了这种异构系统设计：它的每个计算结点由两颗Xeon E5 12核处理器（CPU）
与三颗Xeon Phi 61核协处理器（GPU）组成，CPU+GPU的硬件配置为大规模科学计算提供了强大的驱动力。在桌面
计算机市场上，一般的PC机都配备了专门的图形处理器，这些现代图形处理器，除协助CPU完成
图形渲染方面的任务之外，也支持通用计算，允许PC机用户在显卡上进行通用计算编程。
最新的智能手机也已经开始采用GPU来辅助CPU执行计算，以期为游戏应用提供更强的计算支持。

在更加宏观的层次上，并行硬件一直是提供大规模计算能力的主要技术。互联网上存在着大量的服务器集群，由数十台甚至
上百台独立计算机通过通用网络互联，搭建成的集群系统为大规模事务处理提供了强力支持。由成百上千个高性能
计算结点通过专用网络互联组成的超级计算级，运行着超大规模的科学计算任务。这些宏观计算机系统由独立的计算机结点
组成，每个结点独立并行地执行任务，每个结点又是由并行处理器、协处理器等并行硬件构成的异构系统。

总之，并行化与异构化是当今计算机硬件系统的主流发展趋势，在可以预见的将来，计算机性能的提高将以并行硬件
的驱动与异构硬件的利用为主要手段。

\subsection{并行化与异构化硬件的软件支持}
多核处理器与协处理器为设计实现更高性能的计算机系统提供了硬件支持，如何适应
硬件的发展，有效地利用这些硬件资源，为程序员提供易用的、高效的编程工具，是提高并行硬件应用能力
的关键问题。并行编程工具的设计需要兼顾两个核心特性：\emph{高效性}与\emph{易用性}。
高效性是指并行编程工具必须能够充分开发并行硬件的计算能力，最大程度地利用硬件资源；
易用性是指在有效开发硬件并行能力的前提下，编程工具应该是易用的，并行程序设计的难度与复杂度不能过高。

当前已经有多种并行编程工具得到了广泛使用，这些工具有的
针对多核处理器设计，有的针对分布式存储计算机设计，有的针对异构硬件设计；
有的适用于数据并行问题，有的适用于任务并行问题。
这些广泛应用的并行软件技术包括多线程、消息传递接口、并行程序语言、编译器制导指令等，
它们特点各异，在通用性、适用问题方面都有不同。

多线程（multithreading）技术是在传统串行编程技术的基础上发展起来一种并行编程技术，
它的出现早于多核处理器。一个线程在逻辑上是一个独立指令流，不同线程的指令流可以在单一处理器上交替
执行以隐藏一些耗时较高的操作（如IO），避免处理器空转，提高处理器的吞吐率。
在多核处理器上，多个线程可以真正“并行”地执行。使用多线程编程模型，编程者显式地
将整个任务划分为独立的子任务，不同的子任务在不同的线程中执行，从而利用更多处理器资源，
缩短整个程序的运行时间。多线程支持通常由操作系统（Operating System）提供，是一种非常成熟的并行
编程技术。%% POSIX线程是多线程模型的POSIX标准，Pthreads在多种操作系统上均有实现。

消息传递接口（Message Passing Interface, MPI\upcite{Geist1996}）是一套并行程序库接口规范，
它以多线程技术为基础，定义了线程间
通信的标准方法，最初定位用于分布式内存计算机系统，但也适用于共享内存计算机系统。MPI定义的标准
通信接口功能全面，问题描述能力强大，具被性能高、可扩展性强、可移植性强的特点，长期以来一直都是高
性能计算领域的主要编程工具。

多线程技术与MPI技术都是在已有的串行程序语言之上，通过构建程序库的方式为并行编程提供支持。这种方式的
好处是硬件控制能力强，执行效率高，缺点是受限于已有的编程语言特性，细节隐藏能力差，编程复杂度高。
并行程序语言采用一种不同的思路，从语言层面为并行程序提供支持。并行程序语言一般通过提供特殊的并行语法
结构来表达程序中的并行部分，但在底层实现仍采用传统的多线程与MPI技术，任务并行化的工作由编译器自动完成。
并行编程语言的抽象层次一般较高，更加注重语言的易用性，对编程者隐藏并行硬件细节。并行程序语言一直
是并行软件技术的研究热点，这部分内容将在下一章着重介绍。

编译器制导指令（Compiler Directive）是一种介于并行程序库与并行程序语言之间的并行编程技术，
它允许程序员在源代码中插入专用的制导指令（directive）来指出
程序中的并行部分，并在必要之处加入同步互斥及通信。编译器识别这些制导指令，对程序做自动并行化处理。
编译器也可以视情况忽略这些制导指令，这时程序退化为串行程序。这种技术只需要程序员做简单的制导工作，
具有较好的可移植性，可以根据硬件资源的数量自动调整并行度，缺点在于难以调试，缺乏错误处理，对线程
粒度控制较弱，同时很难应用于非共享内存计算机系统。编译器制导指令技术的代表是OpenMP\upcite{Dagum1998}。

开发协处理器并行能力的技术在学术界与工业界都受到高度关注，发展也十分迅速。Nvidia公司针对自己的GPU
首先提出了CUDA编程架构，使用CUDA C语言对GPU进行编程，
CUDA C是一种C语言的扩展语言\upcite{Nvidia2008}。
CUDA C在一定程度上暴露了GPU的硬件细节，用户对程序行为的控制力强，程序性能较高。著名的
非盈利技术联盟Khronos Group针对异构计算提出了OpenCL标准\upcite{Group2008}，
Nvidia与AMD公司分别在自己的GPU上支持OpenCL
实现。编译器制导指令技术在协处理器上也得到了应用，代表有OpenACC与OpenHMPP。

总体上，并行程序设计的难度远远高于串行程序设计。在基于传统串行程序语言的解决方案中，编程者不仅需要
关注于解决问题的程序逻辑，还需要显式地处理各种并行细节，诸如线程创建、内存管理、消息传递、任务划分等。
并行程序语言从根本上解决了编程难的问题，但现有的实现技术效果仍不理想，多数研究成果只能适用于
特定领域特定问题，通用性有限。相较于并行硬件的发展，并行软件技术的发展处于相对滞后的状态，现阶段
并行软件技术还没有一个完美的解决方案。高效性与易用性的平衡与兼顾仍然是一个亟待解决的关键问题。

\section{课题研究意义}
正如上一小节所说，计算机硬件系统结构的主流发展趋势是并行化与异构化，而开发并行化与异构化硬件的计算能力
需要相应的并行软件技术提供编程工具。未来计算机系统的性能提高，关键就在于如何从软硬件两方面开发计算机系统
的并行执行能力。这其中，并行编程工具既要适应硬件的特性以提高执行效率，又要独立于不同的硬件结构提供易用
的编程界面，高效性是基本要求，在保证高效性的前提下应尽量兼顾易用性。

综上，并行软件工具需要解决的问题有下列三点，其中前两点是实现并行软件的高效性要求，第三点是易用性要求。
\begin{compactitem}
  \item 如何最大限度地开发并行硬件（包括多核通用处理器与协处理器。）的计算能力？
  \item 如何设计编程模型，使异构系统中通用处理器与协处理器更加有效地协调配合？
  \item 如何对用户隐藏计算机系统的并行硬件细节，降低并行程序设计的难度？
\end{compactitem}

本论文着眼于上述并行软件需要解决的三个问题，对并行程序语言展开研究，
设计了一门数据并行程序语言Rat，为编程者提供一个抽象层次高、表达能力强、细节隐藏好的编程界面，大大降低
并行程序设计的难度。并行程序语言从根本上解决并行编程难的问题，对降低并行计算机系统上的应用开发难度、
提高并行计算机可用性具有重要意义。

Rat语言的一个重要设计目标是利用异构硬件系统，
为了保证高效性，在设计过程中充分考虑了GPU的硬件特点，编译得到的程序可以在GPU上高效执行。同时，
借鉴函数式程序语言的优良性质，采用流驱动计算模型，可以有效协调异构硬件工作，能够发掘独立于问题的
程序并行性。这对于利用未来计算机异构硬件系统也也具有积极意义。

%% 采用Rat语言编写的并行程序运行在一个运行时系统之上，该运行时系统可以根据不同的硬件配置采用不同的
%% 运行时策略，这样既保证了对硬件的充分利用，由保证了较强的可移植性，使Rat程序在不同硬件配置下均可
%% 达到比较理想的性能。

\section{主要研究内容}
函数式并行程序语言Rat的研究内容主要分为两方面：前端语法设计与后端编译实现技术。其中前端语法设计着重实现
并行编程工具的易用性，后端编译实现技术着重实现并行编程工具的高效性。

\subsection{并行程序语言语法设计}
Rat语言的语法设计旨在为编程者提供一个通用、易用的并行编程模型，Rat语言具备以下优良特性：
\begin{compactitem}
  \item 抽象层次高。编程者在编程解决问题时只需要关注问题本身的逻辑，无需关注底层的并行实现细节，线程管理、
    内存管理、任务划分等工作由编译器与运行时系统维护。
  \item 表达能力强。Rat提供了并行向量操作，这些操作可以由一组简单的向量原语构造，
    使用这一组有限的并行原语就可以方便地描述一大类数据并行问题。
  %% \item 语法简洁精巧，易学易用。
\end{compactitem}

\subsection{并行程序语言编译技术}
Rat语言的设计目标是兼顾易用性与高效性。易用性由它的语法设计提供，高效性则有赖于它的编译实现技术。
本论文在Rat语言的编译实现技术方面主要包括下列研究点：
\begin{compactitem}
  \item 并行中间语言设计。中间语言Core提供了一种数据并行编程模型，它的指令集结构简单，易于分析和优化，并且在
    并行硬件上有高效实现。
  \item 基于数据流的自动并行化技术，提出一种将数据并行问题转化为向量流的方案，为挖掘程序的并行潜力
    提供一种通用方法。
  \item 开发GPU的并行计算能力。Rat的首个实现采用Nvidia公司的GPU作为并行计算硬件。
    在编译实现过程中着重考虑如何充分挖掘GPU的并行计算能力。
  \item 开发异构硬件的系统工作能力。设计了一个运行时系统，在GPU端执行计算，CPU端实施管理，
    使不同的处理器资源发挥各自所长，提高系统整体性能。
\end{compactitem}

\section{论文结构组织}
本论文设计一门并行程序语言Rat并提出了一套针对CPU/GPU异构计算机系统的编译实现方案。全文结构如下：

第一章介绍了论文的研究背景，指出计算机硬件并行化与异构化的发展趋势，概括了并行软件技术的发展目标，
阐述了本课题的研究意义，简述了本课题的主要研究内容。

第二章介绍了并行软件技术领域的相关研究现状，分析现有研究采用的方法、取得的成果以及存在的不足。

第三章详细说明了Rat语言的语法设计，包括类型系统、并行向量操作、函数式语言特性与C语言交互界面。

第四章说明Rat语言编译实现所采用的关键技术，包括并行中间语言Core的设计、将并行问题转化成向量流的
流探测技术、若干流优化技术与C代码的生成过程。

第五章给出了运行时系统在CPU/GPU异构硬件系统上的实现方案，包括内存管理器与任务调度器的设计。

第六章对论文的工作进行总结，指出了论文的不足以及未来的工作方向。
