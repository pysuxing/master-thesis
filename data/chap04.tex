\chapter{Rat编译实现技术}
第\ref{chap:frontend}章介绍了Rat语言的语法设计，简洁优雅的语法为编程者提供了
良好的编程界面，解决了并行编程工具的易用性问题。那么另一方面，
高效性要依靠语言的编译实现技术解决。

这一章将详细说明Rat语言的编译实现技术。Rat语言编译实现方案的设计，
着力于实现以下几个目标：
\begin{compactitem}
  \item 采用层次化软件设计，提高Rat实现在不同的硬件系统上的可移植性；
  \item 有效开发异构硬件系统的效能，使CPU与GPU并行工作；
  \item 发挥GPU的在数据并行计算方面的硬件优势。
\end{compactitem}

本章的内容结构如下：
第\ref{sec:backend-overview}节介绍Rat语言编译实现的总体方案，展现Rat实现技术采用
的层次化软件设计。
第\ref{sec:parallel-vm}节给出了并行虚拟机CoreVM的设计，并提出了若干高层优化技术。
CoreVM是硬件无关的，也是在多种并行硬件上能够高效实现的，这样，Rat在不同不同
并行硬件上的移植只需要在这些硬件上实现CoreVM即可，同时高层的优化措施也具有硬件无关特性。
第\ref{sec:auto-parallelization}节提出了一种自动并行化方案，该方案可以有效地管理
可用硬件资源，实现任务的动态划分与调度，使CPU与GPU可以并行工作。
第\ref{sec:gpu-optimization}节介绍了针对GPU硬件结构采用的若干优化方法，以提高并行原语
在GPU上的执行效率。

\section{编译实现总体方案}\label{sec:backend-overview}
第\ref{sec:c-interface}节已经提到，Rat编译器是一个源到源编译期，
最终产生C语言代码，将Rat函数转换成合适类型的C语言函数供C程序调用。
图\ref{fig:frontend}给出了从Rat代码到C代码的翻译流程，步骤如下：
\begin{enumerate}
  \item Rat代码经过词法分析器与语法分析器，形成L1语法树。
    L1语法树是Rat代码的直接表示，它包含的结点类型参见表\ref{tbl:l1-ast}。
  \item L1语法树经过L1变换得到L2语法树，L2语法树结构更加简单，包含的结点类型
    更少，参见表\ref{tbl:l2-ast}。
  \item L2语法树经过L2变换得到Core语法树，Core语法树是Core语言的树状表示，而
    Core语言是Rat并行虚拟机CoreVM的语言。Core语法树的结点类型同L2语法树，但对
    L2语法树中的结点做了反柯里化处理。
  \item 在Core语言层面实施若干高层优化技术。
  \item Core语言最后被翻译成C语言程序。
\end{enumerate}

\begin{figure}[tbh]
  \centering
  \includegraphics[height=5cm]{frontend}
  \caption{Rat编译流程}
  \label{fig:frontend}
\end{figure}

\begin{table}[tbh]
  \centering
  \caption{L1语法树结点类型}\label{tbl:l1-ast}
  \begin{tabularx}{\linewidth}{XX}
      \toprule[1.5pt]
      {\hei 结点类型} & {\hei 描述} \\
      \midrule[1pt]
      type-define & 类型定义\\
      object-decl & 对象声明\\
      object-def & 对象定义\\
      object-ref & 对象引用\\
      literal & 字面量\\
      function-app & 函数应用\\
      lambda-exp & 函数定义\\
      conditional & 条件表达式\\
      vector-comprehension & 向量推导\\
      vector-ele-ref & 向量元素引用\\
      vector-slice-ref & 向量片段引用\\
      local-binding & 局部定义\\
      \bottomrule[1.5pt]
    \end{tabularx}
\end{table}

\begin{table}[tbh]
  \centering
  \caption{L2语法树与Core语法树结点类型}\label{tbl:l2-ast}
  \begin{tabularx}{\linewidth}{XX}
      \toprule[1.5pt]
      {\hei 结点类型} & {\hei 描述} \\
      \midrule[1pt]
      object-ref & 对象引用\\
      literal & 字面量\\
      function-app & 函数应用\\
      lambda-exp & 函数定义\\
      conditional & 条件表达式\\
      \bottomrule[1.5pt]
    \end{tabularx}
\end{table}

\section{并行虚拟机设计}\label{sec:parallel-vm}
%% Rat的并行计算能力由向量原语提供，向量原语在多核处理器与GPU上都可以高效实现。
Rat实现方案采用了层次化软件设计，并行虚拟机CoreVM就是这个层次化设计的关键。
CoreVM是一个抽象层次较高的虚拟机，它有下面两个特点：
\begin{compactitem}
  \item CoreVM独立于具体的并行硬件结构设计；
  \item CoreVM在保持高抽象层次的同时也能够很好地描述并行硬件,
    原理上可以在多核处理器以及GPU等不同并行硬件上高效实现。
\end{compactitem}
这样，只需要在不同的并行硬件上实现CoreVM，就可以保证Rat程序
在不同硬件上的可移植性。

第\ref{subsec:core-language}先介绍Core语言，它是并行虚拟机CoreVM运行的指令集，
然后第\ref{subsec:core-optimization}节介绍几种执行Core语言层面执行的优化技术，
%% 最后第\ref{subsec:}给出

\subsection{Core语言}\label{subsec:core-language}
CoreVM上运行Core语言，Core语言是一种结构简单的语言，容易分析，
并且支持若干高层优化技术。

Core语言的指令集庞大，但结构相对简单，只包含两类指令能够：向量原语与标量原语。
其中向量原语一共只有六条，在第\ref{sec:vector-primitives}节中已经
作出详细说明，表\ref{tbl:vector-primitives}中每一个向量原语在Core语言中一条同名向量原语与之对应；
Core语言提供了数量众多的标量原语，功能为基本的算数逻辑运算与常用数学函数，
选取的数学函数集囊括了标准C数学库定义的数学函数。
FIXME：提及附录。

从Core语言指令集的设计不难看出，标量原语提供了数值计算能力，
而向量原语提供了数据并行能力。两类指令构成了一种简单而强大
的计算模型，非常适合表达实际的数据并行问题。

同时，Core语言的设计使得CoreVM可以很容易地在现有并行硬件上实现。
以多核处理器与GPU为例，标量原语可以直接翻译成C语言的库函数，
向量原语在多核处理器上可以通过多线程技术实现，
在GPU上的实现则更加直观，因为向量原语本身就是对GPU STMD计算模型的直接抽象。

%% 表\ref{tbl:scalar-primitives}给出了一些常用的标量原语。
%% \begin{table}
%%   \centering
%%   \caption{标量原语}
%%   \label{tbl:scalar-primitives}
%%   \begin{tabularx}{\linewidth}{cX}
%%     \toprule[1.5pt]
%%     \hei{操作元数} & \hei{标量原语}\\
%%     \midrule[1pt]
%%     一元标量原语 & \par{\texttt{sqrt cbrt exp exp2 exp10 log log2 log10}}\\
%%     二元标量原语 & \par{ }\\
%%     \bottomrule[1.5pt]
%%   \end{tabularx}
%% \end{table}

\subsection{高层优化技术}
在Rat语言的实现过程中，采用了三种高层优化技术。这些优化技术在Core语言的层面
实施，实质上是一些Core语法树到Core语法树的变换。下面分别介绍这三种优化技术。

\subsubsection{存储空间优化}
第\ref{subsec:immutable-object}节已经指出，Rat语言中的所有对象在整个
生命周期中是不可改写的，称为恒值对象。也就是说，每当一个数据操作（标量操作
或向量操作）被施加到一个对象上时，逻辑上都会产生一个新的对象，编程者可以认为
新的对象与原有对象使用不同的存储空间。

恒值对象简化了程序语义，但如果在具体实现中，
为每一个对象都分配新的存储空间显然是不经济的，
在Rat的实现中，采用了三种存储空间优化技术，可以在
保持程序高层语义简洁的同时提高存储空间利用率。
这三种技术分别是：向量内存即时回收（vector memory collection）、向量原语原地执行（execute in-place）、
写时拷贝（copy-on-write）。

首先介绍向量内存即时回收技术。一段程序中往往存在许多的中间对象，
他们在整个生命周期中只被引用一次，作用相当于临时变量。
当对一个对象的最后一次引用结束之后，即使该对象的生命周期还没结束，
但它的存储空间已经可以被回收利用而不影响程序的正确性。也就是说，
在物理实现中，对象占用分配给它的存储空间的时间可以短于它的逻辑生命周期。
重用存储空间意义重大，对存储空间开销很大的长向量数据执行内存回收重用尤其重要。
%% 图\ref{fig:object-lifetime}给出了一个例子说明。
\begin{quotation}
    \kai{
    仍以\ref{subsec:functional-advantages}节中表达式求值问题为例：\\
    \texttt{dot (map f u) (scan g v)}\\

    上述表达式的求值树参见图\ref{fig:expression-tree}。整个计算过程涉及5个向量数据，
    分别是两个输入向量\texttt{u}与\texttt{v}，两个中间向量\texttt{t1}与\texttt{t2}，
    最终结果向量\texttt{result}。其中\texttt{u}与\texttt{v}分别
    在计算\texttt{t1}与\texttt{t2}的时候被引用一次，之后不再被引用，\texttt{t1}与
    \texttt{t2}在计算最终结果\texttt{result}的时候被引用一次，之后不再被引用。
    5个向量的的逻辑生命周期见图\ref{fig:object-lifetime}，图中还给出了各向量
    引用计数随时间的变化情况（以红色标识）以及他们实际占用内存空间的时间区间（以蓝色标识）。
    
    从图\ref{fig:object-lifetime}可以看出，\texttt{result}与\texttt{u}，\texttt{v}的
    存储空间占用时间区间不存在重合，且在\texttt{result}实际占用存储空间的时间段内
    \texttt{u}、\texttt{v}的引用计数都为0。在这种情况下，\texttt{u}、\texttt{v}占用
    的内存空间就可以回收由\texttt{result}重用。
  }
\end{quotation}
\begin{figure}
  \centering
  \includegraphics[scale=0.8]{object-lifetime}
  \caption{对象生命周期与存储空间占用示意图}
  \label{fig:object-lifetime}
\end{figure}

在上例给出的存储空间优化分析中，还有存在另一种优化可能性，那就是有些向量原语可以
原地执行。所谓原地执行，就是向量操作直接在输入向量的内存空间上
写入输出向量，不许要申请新的存储空间。原地执行必须满足一个条件，就是输入向量在本次向量操作之后引用计数变为0，
即在本次向量操作中输入向量是最后一次被引用。
\begin{quotation}
  \kai{
    在图\ref{fig:object-lifetime}所示的生命周期中与存储空间占用情况中，虽然\texttt{t1}与\texttt{u}
    的存储空间占用时间区间存在重合，但由于\texttt{u}在\texttt{map}操作中是最后一次被引用，
    同时，\texttt{map}原语支持原地执行，这时，\texttt{t1}可以直接回收利用\texttt{u}的存储空间。
  }
\end{quotation}

表\ref{tbl:inplace-vp}给出了向量原语对原地执行的支持状况，某些向量原语需要同步操作才能完成原地执行。
\begin{table}
  \centering
  \caption{向量原语的原地执行支持}\label{tbl:inplace-vp}
  \begin{tabularx}{\linewidth}{ZZZ}
    \toprule[1.5pt]
    \hei{向量原语} & \hei{是否支持原地执行} & \hei{是否需要同步}\\
    \midrule[1pt]
    map & $\surd$ & $\times$\\
    slice & $\times$ & --\\
    scan & $\times$ & --\\
    gpermute & $\surd$ & $\surd$\\
    gcopy & $\surd$ & $\surd$\\
    sort & $\times$ & --\\
    zip & $\surd$ & $\times$\\
    concat & $\times$ & --\\
    \bottomrule[1.5pt]
  \end{tabularx}
\end{table}


写时拷贝也称为零拷贝（zero-copy），指某些向量操作虽然逻辑上定义了新的向量，但实际上没有对输入向量进行任何处理，
得到的新向量与原向量内容相同或部分相同，这时新向量就可以直接指向输入向量的内存空间。
这时，逻辑上可能有多个向量指向同一块存储空间。因为前面提到的两种内存优化技术可能
需要改写向量存储空间（指向该空间的某个向量引用计数变为0或有向量原语试图原地执行），
这时视开销情况执行内存拷贝动作或是为改写动作分配新内存。

向量原语对写时拷贝的支持情况参见表\ref{tbl:copy-on-write}。
\begin{table}
  \centering
  \caption{向量原语的写时拷贝支持}\label{tbl:copy-on-write}
  \begin{tabularx}{\linewidth}{ZZ}
    \toprule[1.5pt]
    \hei{向量原语} & \hei{是否支持写时拷贝}\\
    \midrule[1pt]
    map & $\times$\\
    slice & $\surd$ \\
    scan & $\times$\\
    gpermute & $\surd$\\
    gcopy & $\times$\\
    sort & $\times$\\
    zip & $\surd$\\
    concat & $\surd$\\
    \bottomrule[1.5pt]
  \end{tabularx}
\end{table}

%% 上面举例说明了两种存储空间优化技术，下面给出存储空间静态优化算法\ref{alg:memory-optimization}。
%% 算法\ref{alg:memory-optimization}是一种静态优化算法，在编译期完成。
%% \begin{algorithm}
%%   \caption{CoreVM存储空间优化算法}
%%   \label{alg:memory-optimization}
%%   \begin{algorithmic}
%%     \REQUIRE 向量操作$vop$，其输入向量为$v_1, v_2, \cdots, v_n$
%%   \end{algorithmic}
%% \end{algorithm}

\subsubsection{向量原语重排}
向量原语重排（reorder）是指，在某些情况下，相邻的向量操作可以通过交换顺序
减少需要处理的数据总量，从而达到降低线程资源、存储器空间、访存次数等方面的开销，
下面举例说明向量原语重排的应用。
\begin{quotation}
  \kai{
    考虑下面的表达式求值问题：\\
    \texttt{slice (m, n) (map f input)}\\
    该表达式等价于：\\
    \texttt{map f (slice (m, n) input)}\\
    两个表达式语义上等价，但求解过程不同，参见图\ref{fig:vp-reorder}。从图\ref{fig:vp-reorder}
    可以看出，第二个表达式要比第少个表达式多处理一部分数据，这样就能减少需要的线程资源，节省
    存储器带宽，即通过将\texttt{map}原语与\texttt{slice}“重排”执行能够提高效率。
  }
\end{quotation}
\begin{figure}
  \centering
  \subfloat[\texttt{slice (m, n) (map f input)}]{
    \includegraphics[height=4cm]{vp-reorder-1}
  }
  \\
  \subfloat[\texttt{map f (slice (m, n) input)}]{
    \includegraphics[height=4cm]{vp-reorder-2}
  }
  \caption{向量原语重排示例}
  \label{fig:vp-reorder}
\end{figure}

向量原语两两之间的可重排性参见表\ref{tbl:vp-reorder}，
其中每个单元格对应的两个向量原语的执行顺序为“先左边，再上方”。
标注$\surd$的单元格表示，该格对应的两个向量原语应该重排以提高执行效率；
标注--的单元格表示该格对应的两个向量原语可以重排，但不会带来效率提升；
标注$\times$的单元格表示该格对应的两个向量原语不应重排，重排会带来性能损失；
空单元格表示该格对应的两个向量原语不能重排，重排会造成语义错误。
\begin{table}
  \centering
  \caption{向量原语可重排性}\label{tbl:vp-reorder}
  \begin{tabularx}{\linewidth}{|c|Z|Z|Z|Z|Z|c|Z|Z|}
    \hline
    & \texttt{map} & \texttt{slice} & \texttt{concat} & \texttt{zip} &
    \texttt{scan} & \texttt{gpermute} & \texttt{gcopy} & \texttt{sort}\\
    \hline
    \texttt{map} & -- & $\surd$ & & & & -- & $\surd$ & \\
    \hline
    \texttt{slice} & $\times$ & & & & & & & \\
    \hline
    \texttt{concat} & & & & & & & &\\
    \hline
    \texttt{zip} & & & & & & & &\\
    \hline
    \texttt{scan} & & & & & & & &\\
    \hline
    \texttt{gpermute} & -- & & & & & & & \\
    \hline
    \texttt{gcopy} & $\times$ & & & & & & & \\
    \hline
    \texttt{sort} & & & & & & & &\\
    \hline
  \end{tabularx}
\end{table}

\subsubsection{向量原语聚合}
向量原语聚合（fusion）是指，在某些情况下，多个向量操作可以合并成单个向量操作，
从而可以减少访存，节省存储器带宽，同时还能消除访问存储器造成的时延，提高执行速度。
下面举例说明向量原语聚合的应用。
\begin{quotation}
  \kai{
    考虑下面的表达式求值问题：\\
    \texttt{map f (map g input)}\\
    该表达式等价于：\\
    \texttt{map (f . g) input}\\
    两个表达式语义上等价，但求解过程不同，参见图\ref{fig:vp-fusion}。从图\ref{fig:vp-fusion}
    可以看出，第一个表达式比第二个表达式多引入一个中间向量，虽然
    通过前一小节介绍的存储空间优化技术避免为这个中间向量分配新的的存储空间，但仍然会多引入
    一次的向量读与一次向量写。此时，将两个\texttt{map}原语“聚合”成一次能够提高效率。
  }
\end{quotation}
\begin{figure}
  \centering
  \subfloat[\texttt{map f (map g input)}]{
    \includegraphics[height=4cm]{vp-fusion-1}
  }
  \\
  \subfloat[\texttt{map (f . g) input}]{
    \includegraphics[height=4cm]{vp-fusion-2}
  }
  \caption{向量原语聚合示例}
  \label{fig:vp-fusion}
\end{figure}

向量原语之间的可聚合性参见表\ref{tbl:vp-fusion}。
其中每个单元格对应的两个向量原语的执行顺序为“先左边，再上方”。
标注$\surd$的单元格表示，该格对应的两个向量原语应该聚合以提高执行效率；
%% 标注--的单元格表示该格对应的两个向量原语已经经过重排，所以该组合不会出现；
空单元格表示该格对应的两个向量原语不能聚合，聚合会造成语义错误。
\begin{table}
  \centering
  \caption{向量原语可聚合性}\label{tbl:vp-fusion}
  \begin{tabularx}{\linewidth}{|c|Z|Z|Z|Z|Z|c|Z|Z|}
    \hline
    & \texttt{map} & \texttt{slice} & \texttt{concat} & \texttt{zip} &
    \texttt{scan} & \texttt{gpermute} & \texttt{gcopy} & \texttt{sort}\\
    \hline
    \texttt{map} & $\surd$ & $\surd$ & $\surd$ & $\surd$ & & $\surd$ & $\surd$ & \\
    \hline
    \texttt{slice} & $\surd$ & $\surd$ & $\surd$ & $\surd$ & & $\surd$ & & $\surd$\\
    \hline
    \texttt{concat} & $\surd$ & $\surd$ & $\surd$ & $\surd$ & & $\surd$ & $\surd$ & \\
    \hline
    \texttt{zip} & $\surd$ & $\surd$ & $\surd$ & $\surd$ & $\surd$ & $\surd$ & $\surd$ & $\surd$\\
    \hline
    \texttt{scan} & & & & $\surd$ & & & &\\
    \hline
    \texttt{gpermute} & $\surd$ & $\surd$ & $\surd$ & $\surd$ & & $\surd$ & $\surd$ & $\surd$\\
    \hline
    \texttt{gcopy} & $\surd$ & & $\surd$ & $\surd$ & & $\surd$ &  & \\
    \hline
    \texttt{sort} & & & $\surd$ & $\surd$ & & & &\\
    \hline
  \end{tabularx}
\end{table}

\section{自动并行化技术}\label{sec:auto-parallelization}
正如第\ref{sec:parallel-vm}节所说，Rat的并行虚拟机CoreVM被设计为在多种
并行硬件上都能够高效实现，这实现了本章开始提出的三个目标中的第一个。
Rat的第一版实现方案选择Nvidia公司的GPU作为运行CoreVM的并行硬件，
在实现任务自动并行化的时候着力与完成另外两个目标，即充分发掘GPU的并行计算能力与
有效协调CPU与GPU并行工作。

第\ref{subsec:stream-detection}节将首先介绍流探测（stream detection）算法，该算法是一种静态算法，
在编译期执行，搜索向量操作序列中的可并行任务，实施上一节中提出的高层优化技术。
然后第\ref{subsec:runtime-system}节介绍Rat的运行时系统，该系统根据流探测算法
的探测结果，对硬件资源实施管理，在CPU与GPU两端动态地调度并行任务。

\subsection{流探测算法}\label{subsec:stream-detection}
任务的自动并行化一直是一个难题，因为并行问题的固有特征导致不同问题可发掘的并行潜力各不相同，
这使得对与并行问题的求解没有通用的最优化方案。CoreVM的设计使得数据并行问题被分解成
一个个向量操作组成的序列，而这个将并行问题序列化为向量操作的过程，
消除了问题本身的固有特性，同时序列化的向量操作成为一种“通用”的并行问题描述形式，
这为发现问题无关的并行性提供了可能。

流探测算法的功能就是将并行程序转化成向量操作序列，我们将连续的向量操作称之为”流“，
其定义如下：
\begin{definition}
  称施加在某个数据向量上的向量操作序列为程序中任务流，由这个向量操作序列生成的向量数据序列
  称为程序中的向量流。
\end{definition}

在给出流探测算法的正规描述之前，仍以一个并行问题实例进行说明。
\begin{quotation}
  \kai{
    以第\ref{sec:n-body}节中的n-body问题为例，该问题的Core语法树见图\ref{fig:n-body-core}，
    （为清晰起见，该图进行了一定的简化，原始的Core语法树规模更为庞大）。
    从图中可以看出，输入向量\texttt{Cells}（图中用矩形表示）一共被引用了五次，
    从\texttt{Cells}出发，经过一些向量原语的操作，生成了若干个中间变量（图中用椭圆形表示）
    如\texttt{positions}与\texttt{velocities}等。

    通过流探测算法生成的向量流如图\ref{fig:n-body-data-flow}，图中每一个结点
    表示一个向量，每一条边代表某种向量操作。图\ref{fig:n-body-stream}的
    对偶图即为任务流图。
  }
\end{quotation}
\begin{figure}
  \centering
  \includegraphics[scale=0.7]{n-body-core}
  \caption{n-body问题Core语法树}
  \label{fig:n-body-core}
\end{figure}
\begin{figure}
  \centering
  \includegraphics[scale=0.7]{n-body-stream}
  \caption{n-body问题的向量流图}
  \label{fig:n-body--stream}
\end{figure}


\subsection{运行时系统}\label{subsec:runtime-system}
\subsubsection{硬件资源管理器}

\subsubsection{并行任务调度器}

\section{GPU端优化技术}\label{sec:gpu-optimization}

\subsection{寄存器优化}

\subsection{全局存储器优化}

\subsection{共享存储器优化}
