\chapter{Rat运行时系统}

第\ref{chap:compiler}章介绍了Rat的并行虚拟机CoreVM，并提出了一种程序自动并行化方案。
本章将详述CoreVM在CPU/GPU异构计算机系统上的具体实现。
CoreVM实现的整体结构如图\ref{fig:backend}。
\begin{figure}
  \centering
  \includegraphics[height=5cm]{backend}
  \caption{CoreVM在异构计算机系同上的实现}
  \label{fig:backend}
\end{figure}

从图\ref{fig:backend}中可以看出，
CoreVM的实现构建在在运行时系统（Runtime System）之上，而运行时系统由三部分组成：
内存资源管理器（Memory Manager）、并行任务调度器（Task Scheduler）与向量原语驱动（VP Driver）。
第\ref{sec:memory-manager}节介绍内存资源管理器，该组件对整个系统中可用的内存资源实施统一的管理分配。
第\ref{sec:task-scheduler}节介绍并行任务调度器，该组件的输入为编译期静态生成的任务队列，
负责程序运行期动态地将队列中的计算任务发送到GPU上，同时在CPU端协同GPU完成一些辅助计算。
第\ref{sec:vp-driver}节介绍向量原语驱动，也就是向量原语具体硬件上实现，这里采用Nvidia GPU作为硬件平台。

\section{内存资源管理器}\label{sec:memory-manager}
内存资源管理器的功能是，管理CPU端与GPU端的内存空间，对并行任务调度器的内存请求产生响应。
它主要管理两类内存空间，即GPU全局内存（global memory）与CPU端页锁内存（page-locked memory）。

FIXME：第二章要介绍CPU/GPU编程模型。
对于Nvidia GPU来说，GPU上的内存分配与回收都是在CPU端通过特定的API调用完成的，因此，
虽然内存资源本身位于GPU上，但负责GPU内存分配与回收的管理功能却要在CPU端执行。

一般来说，CPU端的内存管理可以直接调用操作系统API完成，但页锁内存需要特殊对待。
页锁内存可以提供一些性能上的优势FIXME：citehere，：
\begin{compactitem}
  \item GPU可以在执行Kernel的同时进行页锁内存与GPU内存之间的数据传输
  \item 某些GPU设备可以直接读取页锁内存从而避免CPU端与GPU端的数据传输
\end{compactitem}
但页锁内存不能被操作系统用来响应正常的页请求，申请过多的页锁内存会导致操作系统性能下降。

\subsection{GPU全局内存管理}
%% 本节介绍GPU全局内存的管理。首先给出几种可以提高内存利用率的优化技术，
%% 然后再简述GPU内存管理的物理实现。
%% Rat程序中对向量内存的使用有以下两个特点，这可以指导内存管理算法的设计。
%% \begin{compactitem}
%%   \item 多个向量对象可能包含相同的内容；
%%   \item 处于同一条流上的向量对象在长度上很可能相等；
%% \end{compactitem}
%% 首先，为了节省内存空间，应该令包含相同内容的向量数据共享物理内存空间，
%% 这可以通过对物理内存空间进行引用计数管理实现；
%% 第二，由于处在同一条流上的向量对象被某些向量操作联系在一起，如果他们的
%% 长度相同，那么位于流前部的向量就可以回收位于流后部的向量的内存空间而无需
%% 重新申请空间。

第\ref{subsec:immutable-object}节已经指出，Rat语言中的所有对象在整个
生命周期中是不可改写的，称为恒值对象。也就是说，每当一个数据操作（标量操作
或向量操作）被施加到一个对象上时，逻辑上都会产生一个新的对象，编程者可以认为
新的对象与原有对象使用不同的内存空间。

恒值对象简化了程序语义，但如果在具体实现中，
为每一个对象都分配新的内存空间显然是不经济的，
在Rat的实现中，采用了三种内存空间优化技术，可以在
保持程序高层语义简洁的同时提高内存空间利用率。
这三种技术分别是：向量内存即时回收（vector memory collection）、向量原语原地执行（execute in-place）、
写时拷贝（copy-on-write）。

\subsubsection{向量内存即时回收}
首先介绍向量内存即时回收技术。一段程序中往往存在许多的中间对象，
他们在整个生命周期中只被引用一次，作用相当于临时变量。
当对一个对象的最后一次引用结束之后，即使该对象的生命周期还没结束，
但它的内存空间已经可以被回收利用而不影响程序的正确性。也就是说，
在物理实现中，对象占用分配给它的内存空间的时间可以短于它的逻辑生命周期。
重用内存空间意义重大，对内存空间开销很大的长向量数据执行内存回收重用尤其重要。
%% 图\ref{fig:object-lifetime}给出了一个例子说明。
\begin{quotation}
    \kai{
    以\ref{subsec:functional-advantages}节中表达式求值问题为例：\\
    \texttt{dot (map f u) (scan g v)}\\

    上述表达式的求值树参见图\ref{fig:expression-tree}。整个计算过程涉及5个向量数据，
    分别是两个输入向量\texttt{u}与\texttt{v}，两个中间向量\texttt{t1}与\texttt{t2}，
    最终结果向量\texttt{result}。其中\texttt{u}与\texttt{v}分别
    在计算\texttt{t1}与\texttt{t2}的时候被引用一次，之后不再被引用，\texttt{t1}与
    \texttt{t2}在计算最终结果\texttt{result}的时候被引用一次，之后不再被引用。
    5个向量的的逻辑生命周期见图\ref{fig:object-lifetime}，图中还给出了各向量
    引用计数随时间的变化情况（以红色标识）以及他们实际占用内存空间的时间区间（以蓝色标识）。
    
    从图\ref{fig:object-lifetime}可以看出，\texttt{result}与\texttt{u}，\texttt{v}的
    内存空间占用时间区间不存在重合，且在\texttt{result}实际占用内存空间的时间段内
    \texttt{u}、\texttt{v}的引用计数都为0。在这种情况下，\texttt{u}、\texttt{v}占用
    的内存空间就可以回收由\texttt{result}重用。
  }
\end{quotation}
\begin{figure}
  \centering
  \includegraphics[scale=0.8]{object-lifetime}
  \caption{对象生命周期与内存空间占用示意图}
  \label{fig:object-lifetime}
\end{figure}

\subsubsection{向量原语原地执行}
在上例给出的内存空间优化分析中，还有存在另一种优化可能性，那就是有些向量原语可以
原地执行。所谓原地执行，就是向量操作直接在输入向量的内存空间上
写入输出向量，不许要申请新的内存空间。原地执行必须满足一个条件，就是输入向量在本次向量操作之后引用计数变为0，
即在本次向量操作中输入向量是最后一次被引用。
\begin{quotation}
  \kai{
    在图\ref{fig:object-lifetime}所示的生命周期中与内存空间占用情况中，虽然\texttt{t1}与\texttt{u}
    的内存空间占用时间区间存在重合，但由于\texttt{u}在\texttt{map}操作中是最后一次被引用，
    同时，\texttt{map}原语支持原地执行，这时，\texttt{t1}可以直接回收利用\texttt{u}的内存空间。
  }
\end{quotation}

表\ref{tbl:inplace-vp}给出了向量原语对原地执行的支持状况，某些向量原语需要同步操作才能完成原地执行。
\begin{table}
  \centering
  \caption{向量原语的原地执行支持}\label{tbl:inplace-vp}
  \begin{tabularx}{\linewidth}{ZZZ}
    \toprule[1.5pt]
    \hei{向量原语} & \hei{是否支持原地执行} & \hei{是否需要同步}\\
    \midrule[1pt]
    map & $\surd$ & $\times$\\
    slice & $\times$ & --\\
    scan & $\times$ & --\\
    gpermute & $\surd$ & $\surd$\\
    gcopy & $\surd$ & $\surd$\\
    sort & $\times$ & --\\
    zip & $\surd$ & $\times$\\
    concat & $\times$ & --\\
    \bottomrule[1.5pt]
  \end{tabularx}
\end{table}

\subsubsection{写时拷贝}
写时拷贝也称为零拷贝（zero-copy），指某些向量操作虽然逻辑上定义了新的向量，但实际上没有对输入向量进行任何处理，
得到的新向量与原向量内容相同或部分相同，这时新向量就可以直接指向输入向量的内存空间。
这时，逻辑上可能有多个向量指向同一块内存空间。因为前面提到的两种内存优化技术可能
需要改写向量内存空间（指向该空间的某个向量引用计数变为0或有向量原语试图原地执行），
这时视开销情况执行内存拷贝动作或是为改写动作分配新内存。

向量原语对写时拷贝的支持情况参见表\ref{tbl:copy-on-write}。
\begin{table}
  \centering
  \caption{向量原语的写时拷贝支持}\label{tbl:copy-on-write}
  \begin{tabularx}{\linewidth}{ZZ}
    \toprule[1.5pt]
    \hei{向量原语} & \hei{是否支持写时拷贝}\\
    \midrule[1pt]
    map & $\times$\\
    slice & $\surd$ \\
    scan & $\times$\\
    gpermute & $\surd$\\
    gcopy & $\times$\\
    sort & $\times$\\
    zip & $\surd$\\
    concat & $\surd$\\
    \bottomrule[1.5pt]
  \end{tabularx}
\end{table}

\subsubsection{GPU全局内存管理算法}
%% 图\ref{fig:gpu-memory-manager}显示GPU全局内存管理器的结构，在GPU全局内存上
%% 申请的内存空间被组织到两个队列中，两个队列分别维护着被占用内存块与空闲内存块。
%% \begin{figure}
%%   \centering
%%   \includegraphics[height=5cm]{gpu-memory-manager}
%%   \caption{GPU全局内存管理器}
%%   \label{fig:gpu-memory-manager}
%% \end{figure}

前面介绍了三种内存空间优化技术，GPU全局内存管理器使用这三种技术管理GPU全局内存
的分配与回收。

算法\ref{alg:gpu-memory-manager}给出了GPU全局内存分配算法
的正规描述。该算法接收一个任务作为输入，为该任务的输出分配内存。
该算法首先检查任务的向量操作是否能够零拷贝执行，如果可以，则直接将任务输入向量的引用计数
增一；若任务的向量操作可以原地执行，而且任务的输入向量引用计数为1，则原地执行；否则，
调用内存分配器分配内存；内存分配器现在空闲内存表中搜索可用内存，如果搜索不到，则退化为调用
GPU提供的内存分配API。
\begin{algorithm}
  \caption{GPU全局内存分配算法}
  \label{alg:gpu-memory-manager}
  \begin{algorithmic}[1]
    \Require 任务$task$
    \Ensure 内存块$mem$，用于内存$t$的结果向量

    \Function{task-mem-alloc}{$task$}
    \State $vop \leftarrow get\_vop(task)$
    \State $mem \leftarrow NULL$
    \State $input \leftarrow get\_input(task)$
    \If{$zero\_copy(vop) = TRUE$}
    \State \Call{inc-mem-ref}{$input$}
    \State $mem \leftarrow input$
    \ElsIf{$exc\_inplace(vop) = TRUE \& mem\_ref(input) = 1$}
    \State $mem \leftarrow input$
    \Else
    \State $mem \leftarrow$ \Call{mem-alloc}{$get\_output\_size(task)$}
    \EndIf
    \State \Return{mem}
    \EndFunction

    \Function{mem-alloc}{$size$}
    \State $mem \leftarrow$ \Call{search-free-memblock}{$size$}
    \If{$mem = NULL$}
    \State $mem \leftarrow$ \Call{gpu-malloc}{$size$}
    \EndIf
    \State \Return{$mem$}
    \EndFunction
  \end{algorithmic}
\end{algorithm}

算法\ref{alg:gpu-memory-collect}给出了GPU全局内存分配算法的正规描述。
该算法接受一个已经完成的任务作为输入
%% \begin{algorithm}
%%   \caption{GPU全局内存回收算法}
%%   \label{alg:gpu-memory-collect}
%%   \begin{algorithmic}[1]
%%   \end{algorithmic}
%% \end{algorithm}

\section{并行任务调度器}\label{sec:task-scheduler}
%% 同时还根据GPU本身的硬件限制（如流处理器数量、单个流处理器线程上限、单个流处理器寄存器综述等）

\section{向量原语的GPU实现}\label{sec:vp-driver}

